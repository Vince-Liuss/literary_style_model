import os
import wandb
from sentence_transformers import SentenceTransformer, losses
from sentence_transformers.training_args import SentenceTransformerTrainingArguments
from sentence_transformers.trainer import SentenceTransformerTrainer
from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator
from datasets import load_dataset
from transformers import EarlyStoppingCallback

# Set environment variable to disable tokenizer parallelism warning
os.environ["TOKENIZERS_PARALLELISM"] = "false"


def load_data(dataset_name):
    """Loads and splits the dataset from the Hugging Face Hub."""
    print(f"Loading dataset '{dataset_name}'...")
    dataset = load_dataset(dataset_name)
    train_dataset = dataset["train"]
    eval_dataset = dataset["validation"]
    test_dataset = dataset["test"]

    # Select only the columns needed for training
    columns_to_keep = ["sentence1", "sentence2", "score"]

    train_dataset = dataset["train"].select_columns(columns_to_keep)
    eval_dataset = dataset["validation"].select_columns(columns_to_keep)
    test_dataset = dataset["test"].select_columns(columns_to_keep)

    print(f"Train dataset size: {len(train_dataset)}")
    print(f"Validation dataset size: {len(eval_dataset)}")
    print(f"Test dataset size: {len(test_dataset)}")
    return train_dataset, eval_dataset, test_dataset


def setup_training_components(model, eval_dataset):
    """Initializes the loss function and the evaluator for training."""
    print("Setting up training components...")
    loss = losses.CosineSimilarityLoss(model)
    evaluator = EmbeddingSimilarityEvaluator(
        sentences1=eval_dataset["sentence1"],
        sentences2=eval_dataset["sentence2"],
        scores=eval_dataset["score"],
        name="style-validation",
    )
    return loss, evaluator


def configure_training_arguments(
    output_dir, train_dataset, train_batch_size, num_train_epochs
):
    """Configures and returns the training arguments with detailed settings."""
    print("Configuring training arguments...")

    steps_per_epoch = len(train_dataset) // train_batch_size
    eval_steps = steps_per_epoch // 5
    save_steps = eval_steps * 4

    print(f"Total training steps per epoch: {steps_per_epoch}")
    print(f"Evaluation will run every {eval_steps} steps.")
    print(f"Model checkpoint will be saved every {save_steps} steps.")

    return SentenceTransformerTrainingArguments(
        output_dir=output_dir,
        num_train_epochs=num_train_epochs,
        per_device_train_batch_size=train_batch_size,
        per_device_eval_batch_size=train_batch_size,
        optim="adamw_torch_fused",
        learning_rate=2e-5,
        warmup_ratio=0.1,
        weight_decay=0.01,
        adam_epsilon=1e-6,
        max_grad_norm=1.0,
        eval_strategy="steps",
        eval_steps=eval_steps,
        save_strategy="steps",
        save_steps=save_steps,
        save_total_limit=3,
        load_best_model_at_end=True,
        metric_for_best_model="eval_style-validation_spearman_cosine",
        greater_is_better=True,
        data_seed=42,
        report_to="wandb",
        logging_steps=1,
        dataloader_num_workers=4,
        torch_compile=True,
    )


def train_model(model, args, train_dataset, loss, evaluator, early_stopping_threshold):
    """Initializes and runs the SentenceTransformerTrainer with an early stopping callback."""
    print("\nInitializing trainer...")

    # Instantiate the early stopping callback with a threshold
    early_stopping_callback = EarlyStoppingCallback(
        early_stopping_patience=3,  # Still keep a patience count
        early_stopping_threshold=early_stopping_threshold,
    )

    trainer = SentenceTransformerTrainer(
        model=model,
        args=args,
        train_dataset=train_dataset,
        loss=loss,
        evaluator=evaluator,
        callbacks=[early_stopping_callback],  # Pass the callback to the trainer
    )

    print("Starting model training...")
    trainer.train()
    return trainer


def evaluate_and_save_model(trainer, test_dataset, final_model_path):
    """Evaluates the best model on the test set and saves it."""
    print("\nTraining complete. Evaluating on the test set...")
    test_evaluator = EmbeddingSimilarityEvaluator(
        sentences1=test_dataset["sentence1"],
        sentences2=test_dataset["sentence2"],
        scores=test_dataset["score"],
        name="style-test",
    )

    # The trainer holds the best model due to load_best_model_at_end=True.
    # We call the test_evaluator directly on this model.
    model = trainer.model
    test_results = test_evaluator(model)  # This returns a dictionary

    # Log the final test score to wandb without printing locally
    if wandb.run:
        # CORRECTED: Use the full metric name generated by the evaluator
        metric_key = f"{test_evaluator.name}_spearman_cosine"
        spearman_score = test_results.get(metric_key, 0.0)
        wandb.log({"final_test_spearman_cosine": spearman_score})

    print(f"\nSaving the best model to {final_model_path}")
    trainer.save_model(final_model_path)
    print("âœ… Done!")


def main():
    """Main function to orchestrate the finetuning process."""
    # --- Configuration ---
    project_name = ""  # Specify your project name here
    model_name = ""  # Specify your model name here, e.g., "sentence-transformers/all-mpnet-base-v2"
    dataset_name = "VibrantVista/StyleScoredPairsDataset-HybridSplit-Final" # Specify your dataset name here
    # --- Hyperparameters ---
    train_batch_size = 64
    num_train_epochs = 5

    # --- Automatic Path & Run Name Configuration ---
    base_output_dir = "your_output_directory_here"  # Replace with your desired output directory
    model_name_short = model_name.split("/")[-1]
    run_name = f"finetune-style-{model_name_short}"

    output_dir = os.path.join(base_output_dir, f"{run_name}-checkpoints")
    final_model_path = os.path.join(base_output_dir, f"{run_name}-final")

    early_stopping_threshold = 0.003  # Set the threshold for improvement

    # --- WandB Initialization ---
    wandb.init(
        project=project_name,
        name=run_name,
        config={
            "model_name": model_name,
            "dataset_name": dataset_name,
            "epochs": num_train_epochs,
            "batch_size": train_batch_size,
            "early_stopping_threshold": early_stopping_threshold,
        },
    )

    # --- Execution ---
    model = SentenceTransformer(model_name)

    train_ds, eval_ds, test_ds = load_data(dataset_name)
    loss, evaluator = setup_training_components(model, eval_ds)
    args = configure_training_arguments(
        output_dir, train_ds, train_batch_size, num_train_epochs
    )
    trainer = train_model(
        model, args, train_ds, loss, evaluator, early_stopping_threshold
    )
    evaluate_and_save_model(trainer, test_ds, final_model_path)

    wandb.finish()


if __name__ == "__main__":
    main()
